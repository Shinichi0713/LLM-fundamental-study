## 従来手法の課題
ここまでわかったことから、なぜ従来のRNN/LSTMやCNNでは現代のLLM（大規模言語モデル）を実現できなかったのか？という視点で、構造的・計算的なボトルネックを整理します。

### RNN / LSTM の限界：【逐次処理と記憶のボトルネック】

RNN系モデル最大の問題は、**「時間は直列である」という物理的制約を計算モデルに持ち込んでしまった点**にあります。これはスケーリング（大規模化）における致命的な足枷となりました。

1. 計算効率の壁（Parallelization Issue）

* **問題点:** 前の単語の計算が終わらないと次の単語の計算ができない（`t` の計算に `t-1` が必須）。
* **LLMへの影響:** 現代のLLMは数兆トークンを学習しますが、RNNではGPUを何千枚並べても、1つの文の処理速度は上がりません。**「並列処理ができない＝大規模学習が現実的な時間で終わらない」** という物理的な壁です。

2. 情報圧縮の限界（Information Bottleneck）

* **問題点:** どんなに長い文章でも、文脈情報をたった一つの固定長ベクトル（隠れ状態 $h_t$）に詰め込もうとします。
* **LLMへの影響:** 長編小説や論文を読み込ませた際、初期の情報が「上書き」されて消えてしまいます。「文脈理解」において、メモリ容量が圧倒的に不足します。

3. 長距離依存の消失（Vanishing Gradient）

* **問題点:** 逆伝播の際、時間ステップを遡るごとに勾配（学習のシグナル）が指数関数的に小さくなります。
* **LLMへの影響:** 「冒頭の伏線が、物語の最後で回収される」ような、離れた関係性を学習できません。LSTMのゲート機構も完全な解決には至りませんでした。

### CNN の限界：【局所性と構造無視】

画像処理で成功したCNNは、「局所的なパターン認識」には強いものの、言語が持つ「大域的な構造」や「順序の厳密さ」と相性が悪い点がありました。

1. 視野の狭さ（Locality bias）

* **問題点:** フィルタサイズ（窓の大きさ）内の単語しか一度に見ることができません。
* **LLMへの影響:** 「文頭」と「文末」の関係など、フィルタサイズを超える長距離の関係性を捉えるには、層を極端に深くする必要がありますが、それでも文全体を俯瞰することは困難です。

2. 語順情報の欠落（Loss of Sequence Order）

* **問題点:** Max-Pooling等の操作により、「重要なキーワードがあるか」は分かっても、「どこにあったか（誰が誰をどうしたか）」という位置情報が失われがちです。
* **LLMへの影響:** 論理的整合性や、複雑な係り受け構造を持つ文章の生成・理解において致命的です。

3. 静的な重み（Static Weights）

* **問題点:** 学習したフィルタの重みは固定されており、入力される文脈に応じて「どこに注目するか」を動的に変えることができません。
* **LLMへの影響:** 「多義語」の処理や、文脈によって重要度が変わる単語のニュアンスを捉えきれません。

### 課題の整理

文章を扱う上での従来モデルでわかった、課題を一覧にします。

| 特徴 | RNN / LSTM | CNN | Transformer (LLM) |
| :--- | :--- | :--- | :--- |
| **計算処理** | **逐次 (遅い・並列化不可)** | 並列化可能 | **超並列 (高速)** |
| **情報の捉え方** | 全過去を1点に圧縮 | 局所的 (窓の中だけ) | **Self-Attention (全単語間の関係を直接計算)** |
| **長距離依存** | 苦手 (勾配消失) | 苦手 (層を深くする必要あり) | **得意 (距離に関係なく一定)** |
| **位置情報** | 逐次処理で暗黙的に保持 | Poolingで失われやすい | **Positional Encodingで明示** |
| **スケーリング** | 困難 | 可能だが言語には不向き | **極めて容易 (Laws of Scaling)** |

