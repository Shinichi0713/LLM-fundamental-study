# 目的

VLM関係の技術を浅く広く収集する。

## VLM-LENS

### 課題

VLMは、あたかもブラックボックスのように、入力と出力の関係性しか見えない存在でした。

従来のVLMの評価は、主に**精度**に基づいて行われてきました。例えば、画像に対する質問応答タスクであれば、正解率が高いほど高性能なモデルと評価されます。

しかし、精度だけでは、VLMがどのような情報を利用して判断しているのか、本当に理解しているのかを判断することはできません。

VLMは、データセットに含まれる**偏り（バイアス）**を利用して、表面的な特徴に頼った判断をしてしまうことがあります。

例えば、「空の写真には必ず鳥が写っている」というデータセットで学習した場合、VLMは空の写真を見ると、鳥が写っていなくても「鳥がいる」と判断してしまう可能性があります。このような場合、精度は高くても、VLMが本質的な理解をしているとは言えません。

### 解決法

VLM-LENSは、VLMの**内部表現**を抽出し、分析・解釈するためのツールキットです。

内部表現とは、VLMが画像やテキストを処理する過程で生成する、数値データの集合です。

この内部表現を分析することで、VLMがどのような情報を重視し、どのように判断しているのかを理解することができます。

VLM-LENSは、以下の課題を解決し、新たな可能性を切り開きます。

* **既存の評価方法の限界の克服**：精度だけでなく、内部表現に基づいた評価を可能にすることで、VLMの本質的な理解度を評価します。
* **モデル固有の複雑さの抽象化**：様々なVLMに対して、統一的なインターフェースを提供することで、モデルごとの複雑な設定や前処理を不要にします。
* **解釈可能性ツールキットの拡張**：TransformerLensなどの既存のツールキットを拡張し、VLMsをサポートすることで、より高度な分析を可能にします。


VLM-LENSを実行した結果は、**SQLiteデータベース**に格納される、モデルの**中間表現（テンソル）**が中心のデータです。** **

あなたの実行結果の `DataFrame`から、以下のことがわかります。

VLM-LENSの出力データの構造** **

1. **メタデータ** **: 実行に関する情報が格納されています。**

* **`id`** **: データのユニークなID。**
* **`name`** **: 使用したモデルの名前（例:** `Salesforce/blip2-opt-2.7b`）。
* **`architecture`** **: モデルのアーキテクチャ（例:** `blip2`）。
* **`timestamp`** **: 実行日時。**
* **`image_path`** **: 入力画像のパス。**
* **`prompt`** **: 入力プロンプト（例:** `"Describe the color in this image in one word."`）。
* **`layer`** **: データを抽出したモデルのレイヤーの名前（例:** `vision_model.post_layernorm`, `language_model.lm_head`）。

1. **中間表現（テンソル）** **: これがVLM-LENSの核心となるデータです。**

* **`tensor`** **: これが抽出された中間表現のデータそのものです。あなたの** `DataFrame`では、`b'PK...'`という `bytes`形式で保存されています。これは、NumPy配列が圧縮され、データベースにバイナリデータとして格納されていることを示しています。
* **`tensor_dim`** **: テンソル（配列）の次元数。**`language_model.lm_head`の `50304`は、語彙サイズに対応している可能性が高いです。** **

なぜデータが `b'PK...'`と表示されるのか？

`b'PK...'`は、`pandas`がSQLiteデータベースからバイナリデータを読み込んだ際に、そのままのバイト文字列として表示しているためです。このバイナリデータは、NumPy配列を `np.save()`などでシリアライズ（直列化）したものです。
