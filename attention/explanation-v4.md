## Attentionã®å†…å®¹ã‚’è§£åƒåº¦é«˜ã‚ã¦ç†è§£

ã“ã‚Œã¯ **ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®æœ¬è³ª** â€” ã€Œã©ã®ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆå˜èªï¼‰ãŒã€ã©ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ã‚’ã©ã‚Œã ã‘å‚ç…§ã—ã¦ã„ã‚‹ã‹ã€ã‚’ç›´æ„Ÿçš„ã«ç†è§£ã™ã‚‹ãŸã‚ã«æœ€é©ãªãƒ†ãƒ¼ãƒã§ã™ã€‚

ä»¥ä¸‹ã«ã€**å…·ä½“ä¾‹ï¼‹ã‚³ãƒ¼ãƒ‰ã§ç¢ºèªã§ãã‚‹Colabå‘ã‘ãƒ‡ãƒ¢** ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

---

## ğŸ§© æ¦‚å¿µã®æ•´ç†ï¼ˆå›³è§£ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰

| è¦ç´                 | å½¹å‰²                                       | ç›´æ„Ÿçš„ãªãŸã¨ãˆ                                       |
| ------------------- | ------------------------------------------ | ---------------------------------------------------- |
| **Query (Q)** | ã€Œä»Šã€ã©ã“ã‚’è¦‹ãŸã„ã‹ï¼Ÿã€ã‚’è¡¨ã™è³ªå•ãƒ™ã‚¯ãƒˆãƒ« | ğŸ‘€ã€Œç§ã¯â€œèµ°ã‚‹â€ã¨ã„ã†å˜èªã‚’ç†è§£ã—ãŸã„ã€             |
| **Key (K)**   | ã€Œè‡ªåˆ†ãŒã©ã‚“ãªæƒ…å ±ã‚’ã‚‚ã£ã¦ã„ã‚‹ã‹ã€ã‚’ç¤ºã™   | ğŸ§ ã€Œç§ã¯â€œçŠ¬â€ã¨ã„ã†åè©ã§ã€ä¸»èªã®æƒ…å ±ã‚’ã‚‚ã£ã¦ã„ã‚‹ã€ |
| **Value (V)** | ã€Œè‡ªåˆ†ã®ä¸­èº«ãã®ã‚‚ã®ï¼ˆä¼ãˆã‚‹å†…å®¹ï¼‰ã€       | ğŸ’¬ã€Œâ€œçŠ¬â€ã¨ã„ã†æ„å‘³ã®ãƒ™ã‚¯ãƒˆãƒ«ã€                     |

ğŸ‘‰ **Attention = Query ãŒ Key ã‚’æ¤œç´¢ã—ã€å¯¾å¿œã™ã‚‹ Value ã‚’é‡ã¿ã¥ã‘ã—ã¦é›†ç´„ã™ã‚‹å‡¦ç†**

---

## ğŸ§  ä¾‹æ–‡ã§ç†è§£ï¼šã€ŒThe dog chased the catã€

| å˜èª             | å½¹å‰²         | ç›´æ„Ÿ                                           |
| ---------------- | ------------ | ---------------------------------------------- |
| **dog**    | ä¸»èªï¼ˆåè©ï¼‰ | â€œè¿½ã†å´â€ã®æƒ…å ±                               |
| **chased** | å‹•è©         | â€œä½•ã‚’ã—ãŸã‹â€ã‚’ç†è§£ã™ã‚‹ã«ã¯ä¸»èªã¨ç›®çš„èªãŒå¿…è¦ |
| **cat**    | ç›®çš„èª       | â€œè¿½ã‚ã‚ŒãŸå´â€ã®æƒ…å ±                           |

> ã€Œchasedã€ã® Query ã¯ã€ã€Œdogã€ã¨ã€Œcatã€ã® Key ã‚’æ¢ã—ã¦ã€
>
> ã€ŒValueï¼ˆä¸­èº«ï¼‰ã€ã‚’åŠ é‡å¹³å‡ã—ã¦è‡ªåˆ†ã®ç†è§£ã‚’ä½œã‚‹ã€‚

---

## ğŸ’» Colabç”¨ï¼šAttentionã‚’æ•°å€¤ã§è¦‹ã‚‹ãƒŸãƒ‹ä¾‹

```python
!pip install transformers torch

from transformers import BertTokenizer, BertModel
import torch

# ãƒ¢ãƒ‡ãƒ«æº–å‚™
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertModel.from_pretrained("bert-base-uncased", output_attentions=True)

# å…¥åŠ›æ–‡
sentence = "The dog chased the cat"
inputs = tokenizer(sentence, return_tensors="pt")

# æ¨è«–å®Ÿè¡Œ
outputs = model(**inputs)

# æœ€å¾Œã®å±¤ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆ12å±¤ä¸­ï¼‰
attentions = outputs.attentions[-1]  # shape: [batch, heads, seq_len, seq_len]
tokens = tokenizer.convert_ids_to_tokens(inputs["input_ids"][0])

# 1ã¤ã®ãƒ˜ãƒƒãƒ‰ã‚’æŠ½å‡ºã—ã¦ç¢ºèª
import pandas as pd
head = 0
attn_matrix = attentions[0, head].detach().numpy()

pd.DataFrame(attn_matrix, index=tokens, columns=tokens)
```

ã“ã‚Œã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€æ¬¡ã®ã‚ˆã†ãªè¡¨ãŒå‡ºã¾ã™ğŸ‘‡

| Queryï¼¼Key       | [CLS] | The  | dog            | chased | the  | cat            | [SEP] |
| ---------------- | ----- | ---- | -------------- | ------ | ---- | -------------- | ----- |
| **chased** | 0.02  | 0.01 | **0.35** | 0.02   | 0.03 | **0.28** | 0.01  |

ã“ã“ã§ï¼š

* è¡ŒãŒ **Queryï¼ˆã©ã®å˜èªãŒæ³¨ç›®ã—ã¦ã„ã‚‹ã‹ï¼‰**
* åˆ—ãŒ **Keyï¼ˆã©ã®å˜èªã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹ï¼‰**
* å€¤ãŒ **é‡ã¿ï¼ˆã©ã‚Œãã‚‰ã„è¦‹ã¦ã„ã‚‹ã‹ï¼‰**

ã¤ã¾ã‚Šã€ã€Œchasedï¼ˆå‹•è©ï¼‰ã€ã¯ä¸»èªã€Œdogã€ã¨ç›®çš„èªã€Œcatã€ã«å¼·ãæ³¨ç›®ã—ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ã€‚

â†’ **å‹•è©ãŒæ–‡ã®æ§‹é€ çš„é–¢ä¿‚ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€ä¸»èªã¨ç›®çš„èªã®æƒ…å ±ã‚’å‚ç…§ã—ã¦ã„ã‚‹ï¼**

---

## ğŸ” å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ

* **Queryï¼š** â€œçŸ¥ã‚ŠãŸã„å´â€ï¼ˆä»Šç†è§£ã—ãŸã„å˜èªï¼‰
* **Keyï¼š** â€œæ¤œç´¢å¯¾è±¡ã®ç´¢å¼•æƒ…å ±â€
* **Valueï¼š** â€œå®Ÿéš›ã«å–ã‚Šå‡ºã™å†…å®¹ï¼ˆæ„å‘³ï¼‰â€
* Attention = ã€Œå•ã„åˆã‚ã›ï¼ˆQï¼‰ã€ãŒã€Œç´¢å¼•ï¼ˆKï¼‰ã€ã§æ¤œç´¢ã—ã€ã€Œå†…å®¹ï¼ˆVï¼‰ã€ã‚’é›†ç´„ã—ã¦ç†è§£ã‚’æ·±ã‚ã‚‹

---

ã”å¸Œæœ›ã‚ã‚Œã°ã€æ¬¡ã®ã‚ˆã†ãªç™ºå±•ã‚‚ã§ãã¾ã™ï¼š

1. ğŸ”¸ BertVizã§ã“ã®æ–‡ã‚’**ç·šã§å¯è¦–åŒ–**ã™ã‚‹ï¼ˆå¯¾è©±çš„è¡¨ç¤ºï¼‰
2. ğŸ”¸ ã€Œcatã€ã‚„ã€Œdogã€ãŒã©ã®å±¤ã§å‹•è©ã¨é–¢ä¿‚ã‚’æŒã¤ã‹ã‚’**å±¤ã”ã¨ã«æ¯”è¼ƒ**
3. ğŸ”¸ æ—¥æœ¬èªBERTã«ç½®ãæ›ãˆã¦ã€ŒçŠ¬ãŒçŒ«ã‚’è¿½ã†ã€æ–‡ã§åŒæ§˜ã®åˆ†æ
