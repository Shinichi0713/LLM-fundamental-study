# CNNはVLMに使えないの？

VLM（画像言語モデル）の画像エンコーダとして、**CNN（畳み込みニューラルネットワーク）**を利用することは**可能**です。実際に、初期のVLMや特定のタスクに特化したモデルでは広く使用されていました。

しかし、現在では高性能なVLMの画像エンコーダとして**ViT (Vision Transformer)** が**主流**となっています。これは、ViTがLLMの基盤であるTransformerとシームレスに連携できるためです。



## 1. 🖼️ CNNを画像エンコーダとして使う場合の仕組み

CNN（例：ResNet, VGGなど）を画像エンコーダとして使う場合、以下のような処理フローとなります。

1. **特徴抽出** : CNNが画像を畳み込み、プーリングすることで、階層的にローカルな特徴を抽出します。
2. **出力形式** : 最終層の出力は、通常、空間情報を持つ **グリッド状の特徴マップ** （例：**$14 \times 14$** の特徴量グリッド）または固定長の**単一ベクトル**になります。
3. **VLMへの入力** :

* **グリッドの場合** : その特徴マップを**「画像トークン」のシーケンス**として平坦化し、テキストエンコーダに渡す。
* **単一ベクトル** : 画像全体を表すベクトルとしてテキスト特徴量と結合する。

### 📌 CNNの主な課題

* **グローバルな関係の認識が弱い** : CNNの畳み込みはローカルな操作であるため、画像内の遠く離れた領域間の**直接的な関係**を捉えるのが苦手です。
* **シーケンス統合の複雑さ** : CNNの出力をTransformerの入力形式（シーケンス）に変換する際、追加の処理や特別なアテンション層（例: Faster R-CNNベースの物体検出特徴）が必要になることがあります。



## 2. ⚡️ ViTが主流となった理由（CNNに対する優位性）

ViTは、CNNが持つ上記のような課題を、Transformerの特性を活かして解決しました。

| **特徴**        | **ViT (Vision Transformer)**                                                      | **CNN (例: ResNet)**                                                                                             |
| --------------------- | --------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- |
| **入力処理**    | 画像を固定サイズの**パッチ（トークン）**に分割し、線形に埋め込む。                      | 画像全体を**階層的なフィルタ（カーネル）**で処理する。                                                                 |
| **特徴抽出**    | **自己注意機構**のみを使用。                                                      | **畳み込み**と**プーリング**を使用。                                                                       |
| **画像理解**    | **グローバルな関係**を直接計算できるため、画像全体での文脈理解に優れる。          | **ローカルな関係**の抽出に優れるが、グローバルな関係は深い層で間接的にしか捉えられない。                         |
| **LLMとの相性** | テキストトークンと同じ**Transformerブロック**で処理できるため、統合がシームレス。 | 異なる構造であるため、テキスト側に特徴を合わせ込むための複雑な**クロスアテンション**機構が必要となることが多い。 |

要するに、ViTを使うことで、画像とテキストを**「両方ともトークンシーケンス」**として扱いやすくなり、LLMの成功体験をそのままVLMに応用しやすくなったため、現在では主流となっています。

---

著者は暇があればgithubいじってます。 LLM関係でしたら以下が作品です。 宜しければご覧ください。

https://github.com/Shinichi0713/LLM-fundamental-study

