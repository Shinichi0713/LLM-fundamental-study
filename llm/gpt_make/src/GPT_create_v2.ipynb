{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "前回を受けてGPTをもう少し精度アップさせることを狙う\n",
        "\n",
        "- トークナイザを文字化けしない対応品に変更\n",
        "- GPTをRoPE、RSMノルムレイヤに変更"
      ],
      "metadata": {
        "id": "0rOwo3NcNiYd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFohTQoZNgk-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "\n",
        "# 1. 設定\n",
        "MODEL_NAME = \"elyza/ELYZA-japanese-Llama-2-7b\" # 既存のトークナイザを利用（自作の場合は前回のMockを使用）\n",
        "DATASET_NAME = \"allenai/c4\"\n",
        "SUBSET = \"ja\"        # 日本語を指定\n",
        "SEQ_LEN = 12 * 4          # シーケンス長\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# 2. トークナイザの準備\n",
        "# ※ Llama3のように語彙数が多いものを使いたい場合は \"meta-llama/Meta-Llama-3-8B\" 等を指定\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "# 3. カスタムデータセットクラス (ストリーミング対応)\n",
        "class GPTPretrainingDataset(IterableDataset):\n",
        "    def __init__(self, dataset, tokenizer, seq_len):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __iter__(self):\n",
        "        # 連続したテキストをトークナイズして連結し、SEQ_LENごとに切り出す\n",
        "        buffer = []\n",
        "        for example in self.dataset:\n",
        "            text = example['text']\n",
        "            # トークナイズ（特殊トークンなし、パディングなし）\n",
        "            tokens = self.tokenizer.encode(text, add_special_tokens=False)\n",
        "            buffer.extend(tokens)\n",
        "\n",
        "            # バッファがSEQ_LEN分溜まったら取り出す\n",
        "            while len(buffer) >= self.seq_len:\n",
        "                chunk = buffer[:self.seq_len]\n",
        "                buffer = buffer[self.seq_len:]\n",
        "\n",
        "                # GPT学習用：input_ids と labels を作成\n",
        "                # ラベルは入力のコピー（学習ループ内でずらすか、ここでずらす）\n",
        "                input_tensor = torch.tensor(chunk, dtype=torch.long)\n",
        "\n",
        "                yield {\n",
        "                    \"input_ids\": input_tensor,\n",
        "                    \"labels\": input_tensor.clone()\n",
        "                }\n",
        "\n",
        "# 4. データのロード (Streamingモード)\n",
        "print(\"mC4の日本語データをストリーミング中...\")\n",
        "raw_dataset = load_dataset(\n",
        "    DATASET_NAME,\n",
        "    data_files={'train': 'multilingual/c4-ja.*.json.gz'}, # 日本語ファイルを指定\n",
        "    split=\"train\",\n",
        "    streaming=True\n",
        ")\n",
        "\n",
        "# 5. インスタンス化とDataLoader\n",
        "gpt_dataset = GPTPretrainingDataset(raw_dataset, tokenizer, SEQ_LEN)\n",
        "train_loader = DataLoader(gpt_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 6. 動作確認\n",
        "print(\"最初のバッチを取得中...\")\n",
        "for i, batch in enumerate(train_loader):\n",
        "    print(f\"\\n--- Batch {i+1} ---\")\n",
        "    print(f\"Shape: {batch['input_ids'].shape}\") # [Batch, SEQ_LEN]\n",
        "\n",
        "    # 最初のサンプルの最初の50文字分をデコードして表示\n",
        "    sample_text = tokenizer.decode(batch['input_ids'][0][:20])\n",
        "    print(f\"Decoded Text Sample:\\n{sample_text}...\")\n",
        "\n",
        "    if i == 2: # 3バッチ分確認して終了\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ====================================================================\n",
        "# ハイパーパラメータ設定 (小規模モデル用)\n",
        "# ====================================================================\n",
        "VOCAB_SIZE = 50       # 語彙サイズ\n",
        "\n",
        "EMBED_DIM = 64        # 埋め込み次元 (d_model)\n",
        "NUM_HEADS = 4         # Attention Headの数\n",
        "NUM_LAYERS = 3        # Transformer Decoderブロックの層数\n",
        "FFN_HIDDEN_DIM = EMBED_DIM * 2 # FFNの隠れ層の次元\n",
        "\n",
        "# MoE関連 (オプション)\n",
        "USE_MOE = False       # MoEを使用するかどうか\n",
        "NUM_EXPERTS = 4       # MoEのエキスパート数\n",
        "TOP_K = 2             # MoEで活性化するエキスパート数\n",
        "MOE_LOSS_COEF = 0.01  # ロードバランシング損失の係数\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 100\n",
        "\n",
        "# 特殊トークンID\n",
        "PAD_TOKEN_ID = 0\n",
        "CLS_TOKEN_ID = 1 # GPTでは通常不要だが、例示のため含める\n",
        "MASK_TOKEN_ID = 2 # GPTでは通常不要だが、MLMのデータ生成を想定\n",
        "BOS_TOKEN_ID = 3 # Begin Of Sequence (通常はこれが使われる)\n",
        "EOS_TOKEN_ID = 4 # End Of Sequence\n",
        "\n",
        "# デバイス設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "-UjWA1rGN9pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "# 特殊トークンID\n",
        "PAD_TOKEN_ID = 0\n",
        "CLS_TOKEN_ID = 1 # GPTでは通常不要だが、例示のため含める\n",
        "MASK_TOKEN_ID = 2 # GPTでは通常不要だが、MLMのデータ生成を想定\n",
        "BOS_TOKEN_ID = 3 # Begin Of Sequence (通常はこれが使われる)\n",
        "EOS_TOKEN_ID = 4 # End Of Sequence\n",
        "\n",
        "\n",
        "def rotate_half(x):\n",
        "    # x: (..., dim)\n",
        "    x1 = x[..., ::2]\n",
        "    x2 = x[..., 1::2]\n",
        "    return torch.stack((-x2, x1), dim=-1).flatten(-2)\n",
        "\n",
        "def apply_rope(q, k, seq_len, device):\n",
        "    \"\"\"\n",
        "    q, k: (batch, heads, seq_len, head_dim)\n",
        "    \"\"\"\n",
        "    head_dim = q.size(-1)\n",
        "    assert head_dim % 2 == 0, \"RoPE requires even head_dim\"\n",
        "\n",
        "    # 周波数\n",
        "    theta = 10000 ** (-torch.arange(0, head_dim, 2, device=device) / head_dim)\n",
        "    positions = torch.arange(seq_len, device=device)\n",
        "\n",
        "    freqs = torch.einsum(\"i,j->ij\", positions, theta)  # (seq_len, head_dim/2)\n",
        "    sin = freqs.sin()[None, None, :, :]\n",
        "    cos = freqs.cos()[None, None, :, :]\n",
        "\n",
        "    # 偶奇次元に適用\n",
        "    q_rot = (q[..., ::2] * cos) + (rotate_half(q)[..., ::2] * sin)\n",
        "    k_rot = (k[..., ::2] * cos) + (rotate_half(k)[..., ::2] * sin)\n",
        "\n",
        "    q = torch.cat([q_rot, q[..., 1::2]], dim=-1)\n",
        "    k = torch.cat([k_rot, k[..., 1::2]], dim=-1)\n",
        "\n",
        "    return q, k\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        self.q_linear = nn.Linear(embed_dim, embed_dim)\n",
        "        self.k_linear = nn.Linear(embed_dim, embed_dim)\n",
        "        self.v_linear = nn.Linear(embed_dim, embed_dim)\n",
        "        self.out_linear = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        q = self.q_linear(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.k_linear(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.v_linear(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # ===== RoPE を適用 =====\n",
        "        q, k = apply_rope(q, k, seq_len, x.device)\n",
        "\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.matmul(attention_weights, v)\n",
        "\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)\n",
        "        output = self.out_linear(context)\n",
        "        return output\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm = x.pow(2).mean(dim=-1, keepdim=True)\n",
        "        x = x * torch.rsqrt(norm + self.eps)\n",
        "        return self.weight * x\n",
        "\n",
        "class SwiGLU(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.w2 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.w3 = nn.Linear(hidden_dim, dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w3(F.silu(self.w1(x)) * self.w2(x))\n",
        "\n",
        "class Expert(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.w2 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.w3 = nn.Linear(hidden_dim, dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w3(F.silu(self.w1(x)) * self.w2(x))\n",
        "\n",
        "\n",
        "# 1.4. MoELayer (MoE オプション時)\n",
        "class MoELayer(nn.Module):\n",
        "    def __init__(self, dim, num_experts, top_k, expert_hidden_dim=None):\n",
        "        super().__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.top_k = top_k\n",
        "        hidden_dim = expert_hidden_dim if expert_hidden_dim is not None else dim * 2\n",
        "\n",
        "        self.experts = nn.ModuleList([Expert(dim, hidden_dim) for _ in range(num_experts)])\n",
        "        self.gate = nn.Linear(dim, num_experts)\n",
        "\n",
        "    def forward(self, x):\n",
        "        original_shape = x.shape\n",
        "        x = x.view(-1, original_shape[-1])\n",
        "        N_tokens = x.size(0)\n",
        "\n",
        "        gate_logits = self.gate(x)\n",
        "        gate_weights = F.softmax(gate_logits, dim=-1)\n",
        "\n",
        "        top_k_weights, top_k_indices = torch.topk(gate_weights, self.top_k, dim=-1)\n",
        "        top_k_weights = top_k_weights / top_k_weights.sum(dim=-1, keepdim=True)\n",
        "\n",
        "        final_output = torch.zeros_like(x)\n",
        "\n",
        "        # ロードバランシング損失\n",
        "        expert_usage_one_hot = F.one_hot(top_k_indices, num_classes=self.num_experts).sum(dim=1).float()\n",
        "        expert_router_prob = gate_weights.sum(dim=0) / N_tokens\n",
        "        expert_fraction_routed = expert_usage_one_hot.sum(dim=0) / N_tokens\n",
        "        load_balancing_loss = (expert_router_prob * expert_fraction_routed).sum()\n",
        "\n",
        "        for k in range(self.top_k):\n",
        "            expert_index = top_k_indices[:, k]\n",
        "            weight = top_k_weights[:, k]\n",
        "\n",
        "            for i in range(self.num_experts):\n",
        "                mask = (expert_index == i)\n",
        "                if not mask.any():\n",
        "                    continue\n",
        "                expert_input = x[mask]\n",
        "                expert_output = self.experts[i](expert_input)\n",
        "                weighted_output = expert_output * weight[mask].unsqueeze(1)\n",
        "                final_output[mask] += weighted_output\n",
        "\n",
        "        final_output = final_output.view(original_shape)\n",
        "        return final_output, load_balancing_loss\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ffn_hidden_dim,\n",
        "                 use_moe=False, num_experts=None, top_k=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm1 = RMSNorm(embed_dim)\n",
        "        self.attention = SelfAttention(embed_dim, num_heads)\n",
        "        self.norm2 = RMSNorm(embed_dim)\n",
        "\n",
        "        self.use_moe = use_moe\n",
        "        if use_moe:\n",
        "            self.ffn_or_moe = MoELayer(embed_dim, num_experts, top_k, ffn_hidden_dim)\n",
        "        else:\n",
        "            self.ffn_or_moe = SwiGLU(embed_dim, ffn_hidden_dim)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = x + self.attention(self.norm1(x), mask)\n",
        "\n",
        "        if self.use_moe:\n",
        "            ffn_out, moe_loss = self.ffn_or_moe(self.norm2(x))\n",
        "            x = x + ffn_out\n",
        "            return x, moe_loss\n",
        "        else:\n",
        "            x = x + self.ffn_or_moe(self.norm2(x))\n",
        "            return x, None\n",
        "\n",
        "\n",
        "# ====================================================================\n",
        "# 2. GPTモデル本体\n",
        "# ====================================================================\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, vocab_size, seq_len, embed_dim, num_heads, num_layers, ffn_hidden_dim,\n",
        "                 use_moe=False, num_experts=None, top_k=None):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # トークン埋め込み層\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_TOKEN_ID)\n",
        "        # 位置埋め込み層\n",
        "        self.position_embedding = nn.Embedding(seq_len, embed_dim)\n",
        "\n",
        "        # Transformer Decoderブロックのスタック\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecoderBlock(embed_dim, num_heads, ffn_hidden_dim, use_moe, num_experts, top_k)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # 最終のLayer Normalization (出力前)\n",
        "        self.final_norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        # 出力層 (語彙サイズへの線形変換)\n",
        "        self.lm_head = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "        self.use_moe = use_moe\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # input_ids: (batch_size, seq_len)\n",
        "\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "\n",
        "        # トークン埋め込み\n",
        "        token_embeds = self.token_embedding(input_ids)\n",
        "\n",
        "        # 位置埋め込み (torch.arangeで位置IDを生成)\n",
        "        position_ids = torch.arange(0, seq_len, dtype=torch.long, device=input_ids.device)\n",
        "        position_embeds = self.position_embedding(position_ids)\n",
        "\n",
        "        # 埋め込みの合計\n",
        "        x = token_embeds + position_embeds\n",
        "\n",
        "        # マスクの作成 (未来のトークンを参照しないようにする)\n",
        "        # causal_mask: (seq_len, seq_len) の下三角行列\n",
        "        causal_mask = torch.tril(torch.ones((seq_len, seq_len), device=input_ids.device)).bool()\n",
        "        # パディングマスクはここでは考慮しない (MLMデータセットで対応)\n",
        "\n",
        "        total_moe_aux_loss = 0.0\n",
        "\n",
        "        # Decoderブロックを順に適用\n",
        "        for layer in self.decoder_layers:\n",
        "            output, moe_aux_loss = layer(x, causal_mask)\n",
        "            x = output\n",
        "            if self.use_moe and moe_aux_loss is not None:\n",
        "                total_moe_aux_loss += moe_aux_loss\n",
        "\n",
        "        # 最終Layer Normalization\n",
        "        x = self.final_norm(x)\n",
        "\n",
        "        # 言語モデルヘッド (logits)\n",
        "        logits = self.lm_head(x) # (batch_size, seq_len, vocab_size)\n",
        "\n",
        "        return logits, total_moe_aux_loss\n"
      ],
      "metadata": {
        "id": "byteHLG7ONZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "import os\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "save_dir = \"gpt_checkpoints\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# 1. トークナイザーの「本当の」語彙数を取得\n",
        "# 特殊トークンを含めた全語彙数を使わないと Embedding で IndexError になります\n",
        "actual_vocab_size = len(tokenizer)\n",
        "\n",
        "# 2. モデルの再定義\n",
        "# embed_dim や ffn_hidden_dim はお好みで調整してください\n",
        "model = GPT(\n",
        "    vocab_size=actual_vocab_size,\n",
        "    seq_len=SEQ_LEN,           # データセットの SEQ_LEN と完全に一致させる\n",
        "    embed_dim=256,\n",
        "    num_heads=8,\n",
        "    num_layers=6,\n",
        "    ffn_hidden_dim=1024\n",
        ").to(device)\n",
        "\n",
        "print(f\"Corrected Vocab Size: {actual_vocab_size}\")\n",
        "print(f\"Max Sequence Length: {SEQ_LEN}\")\n",
        "\n",
        "\n",
        "# 2. オプティマイザとスケジューラ\n",
        "# AdamWはLLM学習の標準\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
        "\n",
        "# 学習率を徐々に上げ、その後下げるスケジューラ\n",
        "num_training_steps = 10000 # ストリーミングなのでステップ数で定義\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"cosine\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=500,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "# 3. 損失関数 (PADトークンを無視)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "# --- 4. 学習ループ ---\n",
        "model.train()\n",
        "step = 0\n",
        "running_loss = 0.0\n",
        "\n",
        "print(f\"学習を開始します (Device: {device})\")\n",
        "\n",
        "# ストリーミングDataLoaderを回す\n",
        "for batch in tqdm(train_loader, total=num_training_steps):\n",
        "# for batch in train_loader:\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    labels = batch[\"labels\"].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 順伝播\n",
        "    # logits: [Batch, Seq, Vocab]\n",
        "    logits, _ = model(input_ids)\n",
        "\n",
        "    # --- 重要：GPTの次単語予測（Causal LM）の計算 ---\n",
        "    # 入力の 0~N-1 番目を使って、ラベルの 1~N 番目を当てる\n",
        "    #\n",
        "    shift_logits = logits[:, :-1, :].contiguous().view(-1, tokenizer.vocab_size)\n",
        "    shift_labels = labels[:, 1:].contiguous().view(-1)\n",
        "\n",
        "    loss = criterion(shift_logits, shift_labels)\n",
        "\n",
        "    # 逆伝播\n",
        "    loss.backward()\n",
        "\n",
        "    # 勾配クリッピング (学習の安定化)\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    step += 1\n",
        "\n",
        "    # 定期的にログ表示とモデル保存\n",
        "    if step % 500 == 0:\n",
        "        avg_loss = running_loss / 500\n",
        "        print(f\"Step {step}/{num_training_steps} - Loss: {avg_loss:.4f}\")\n",
        "        running_loss = 0.0\n",
        "\n"
      ],
      "metadata": {
        "id": "H40OiqZIOSJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iU8R_g4LOjwQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}