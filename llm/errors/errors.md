# 付録

## 学習時に起こりやすいエラー
PyTorchでの開発中、特にGoogle Colabなどのリソース制限がある環境や、データの次元が複雑なモデルを扱う際によく遭遇するエラーを分類してリストアップします。


### 1. 形状・次元に関するエラー (Shape Errors)

最も頻繁に発生するエラーです。層と層の間でデータの形が合わない場合に起こります。

* **`RuntimeError: size mismatch, m1: [a x b], m2: [c x d]`**
* **原因**: 全結合層（`nn.Linear`）の入力サイズが、前の層の出力サイズと一致していない。
* **対策**: `m1`の列数`b`と`m2`の行数`c`を一致させる。直前に`Flatten`を入れているか確認。


* **`RuntimeError: Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3]...`**
* **原因**: 畳み込み層（`nn.Conv2d`）に3次元（C, H, W）の画像1枚をそのまま渡している。
* **対策**: バッチ次元を追加して4次元（B, C, H, W）にする必要がある。`image.unsqueeze(0)` を使用。


### 2. デバイスに関するエラー (Device Errors)

CPUとGPU（CUDA）が混在したときに発生します。

* **`RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!`**
* **原因**: モデルはGPUにあるのに、入力データがCPUにある（またはその逆）。
* **対策**: `data = data.to(device)` や `model = model.to(device)` を徹底する。


* **`RuntimeError: CUDA out of memory (OOM)`**
* **原因**: GPUのメモリ（VRAM）が不足。大きな画像サイズやバッチサイズが原因。
* **対策**: バッチサイズを下げる。`with torch.no_grad():` を使って不要な勾配計算を消す。Colabの「ランタイムを解除」してメモリを解放する。


### 3. 勾配・計算グラフに関するエラー (Gradient Errors)

* **`RuntimeError: trying to backward a second time...`**
* **原因**: 1つの `forward` に対して `backward()` を2回実行しようとした。
* **対策**: 通常はループ内で `optimizer.zero_grad()` を忘れていないか確認。


* **`RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn`**
* **原因**: 勾配が必要な計算（学習）なのに、計算グラフが途切れている。
* **対策**: `with torch.no_grad():` の中で `loss.backward()` を呼んでいないか、テンソルを途中で `.numpy()` に変換していないか確認。



### 4. 損失関数に関するエラー (Loss Function Errors)

* **`RuntimeError: 1D target tensor expected, multi-target not supported`**
* **原因**: `nn.CrossEntropyLoss` のターゲット（正解）に、One-hotベクトルを渡している。
* **対策**: PyTorchのCrossEntropyは、クラス番号のラベル（0, 1, 2...）を期待する。`[batch_size]` の形状に修正。


* **`ValueError: Target size (torch.Size([64])) must be the same as input size (torch.Size([64, 1]))`**
* **原因**: `nn.MSELoss` や `nn.BCELoss` で、予測と正解の次元が微妙に違う（次元が1つ多い/少ない）。
* **対策**: `outputs.squeeze()` や `labels.view_as(outputs)` で形状を揃える。



### 5. データロードに関するエラー (DataLoader Errors)

* **`BrokenPipeError` / `RuntimeError: DataLoader worker (pid XXX) is killed by signal: Killed**`
* **原因**: `num_workers` が大きすぎて、メモリ不足で子プロセスが死んだ。
* **対策**: `num_workers=0` に設定してみる（特にWindowsやColabのメモリ制限時）。


## デバッグのコツ

AI開発におけるデバッグは、通常のソフトウェア開発とは異なり、 **「ロジック（コード）のバグ」** に加えて **「データ（統計）のバグ」** や **「モデル（学習）のバグ」** が複雑に絡み合います。

効率的に原因を特定するためのコツと、その根拠を整理して解説します。


### 1. 入出力（Shape）の徹底的な確認

**コツ：** 各レイヤーや処理の前後で、データの「形状（Shape）」を必ず表示（print）する。

* **根拠：** AI（特にディープラーニング）のエラーの多くは、行列計算の不一致です。
全結合層の公式  においても、 の列数と  の行数が一致していなければ計算不能になります。プログラムは動いても、意図しないブロードキャスト（自動補完）によって数値が歪むこともあるため、形状の確認は「計算の整合性」を保証する唯一の手段です。


### 2. 小さなデータセットで「過学習」を試す

**コツ：** 数件〜数十件程度の極小データだけで学習させ、損失（Loss）がほぼゼロになるか確認する。

* **根拠：** もし数件のデータですら誤差が減らないのであれば、データそのものが壊れているか、モデルの構造に致命的なミスがある（例：活性化関数の選択ミス、学習率が異常に高いなど）と判断できます。
「膨大なデータで学習がうまくいかない」のか「そもそもコードが間違っている」のかを**切り分ける**ための強力なテストになります。


### 3. 「再現性」の確保（Seed値の固定）

**コツ：** 乱数シード（Random Seed）を固定し、何度実行しても同じ結果が出るようにする。

* **根拠：** AI開発では、重みの初期値やデータのシャッフルに乱数が使われます。エラーが「時々出る」状態では、修正が有効だったのか、たまたま運が良かったのか判断できません。
科学的なデバッグの基本は**「条件の同一化」**です。シードを固定することで、初めて変数の変更による影響を正しく比較できるようになります。


### 4. 学習曲線の可視化（LossとAccuracy）

**コツ：** 数値だけでなく、Loss（損失）とAccuracy（正解率）の推移をグラフにする。

* **根拠：** 数値の羅列では気づけない「異常」がグラフには現れます。
* **Lossが突然跳ね上がる：** 学習率が大きすぎて、解を飛び越している。
* **Lossが全く変わらない：** 勾配消失が起きている。
これらは「動作エラー」ではないためログには出ませんが、グラフを見れば**「数学的なエラー」**として一目で特定できます。


### 5. データの「中身」を抜き打ち検査する

**コツ：** 前処理後のデータを数件、人間が見て理解できる形式（画像なら表示、テキストなら印字）で確認する。

* **根拠：** 「GIGO（Garbage In, Garbage Out：ゴミを入れたらゴミが出てくる）」の原則です。
正規化のミスで数値がすべて0になっていたり、ラベルが1つずつズレていたりしても、プログラムはエラーを吐かずに「意味のない学習」を続けてしまいます。**「人間から見てデータが正しいか」**を確認することは、アルゴリズムを疑う前の必須ステップです。

## 用語リスト

AIやLLM（大規模言語モデル）の世界は進化が速く、新しい用語が次々と登場します。全体像を把握しやすいように、いくつかのカテゴリーに分けて主要な用語をリストアップしました。


## 1. モデルの構造・基礎概念

AIの「脳」そのものに関する用語です。

* **Transformer（トランスフォーマー）**: 現在のLLMの基盤となっているアーキテクチャ。文中の単語同士の関係性を同時に計算できるのが特徴。
* **Attention（アテンション / 注意機構）**: Transformerの中核技術。文中の「どの単語が重要か」を特定する仕組み。
* **Parameters（パラメータ）**: AIが学習によって調整する「重み」の値。一般的に数が多いほど高性能（GPT-4は数兆規模と言われる）。
* **Token（トークン）**: テキストを処理する最小単位。単語や文字の断片。LLMの料金計算や制限（コンテキストウィンドウ）の基準。
* **Context Window（コンテキストウィンドウ）**: モデルが一度に処理できる情報の長さ。これが長いほど、大量の書類を一気に読み込める。


## 2. 学習・チューニング手法

モデルをどう作り、どう賢くするかに関する用語です。

* **Pre-training（事前学習）**: インターネット上の膨大なデータを使って、言葉の並びを予測できるようにする最初の訓練。
* **Fine-tuning（ファインチューニング）**: 特定の用途（医療、法律、社内規定など）に合わせて、モデルを再学習させて専門性を高めること。
* **RLHF (Reinforcement Learning from Human Feedback)**: 人間がAIの回答を評価し、「人間にとって好ましい回答」をするように調整する強化学習。
* **LoRA (Low-Rank Adaptation)**: 少ない計算資源で効率的にファインチューニングを行う手法。


## 3. 実行・推論・活用技術

実際にAIを使う段階で出てくる用語です。

* **Prompt Engineering（プロンプトエンジニアリング）**: AIから良い回答を引き出すための指示文（プロンプト）の工夫。
* **RAG (Retrieval-Augmented Generation / 検索拡張生成)**: 最新情報や社内文書を外部データベースから検索し、それを元にAIに回答させる仕組み。AIの「知ったかぶり（ハルシネーション）」を防ぐ最重要技術。
* **Hallucination（ハルシネーション / 幻覚）**: AIが事実に基づかない、もっともらしい嘘をつく現象。
* **Temperature（温度パラメータ）**: 回答の「創造性」を調整する値。低いと正確で固い回答、高いと多様でクリエイティブな回答になる。


## 4. 開発・評価・運用

AIシステムを構築する際に必要な用語です。

* **Vector Database（ベクトルデータベース）**: テキストや画像を「意味」として計算可能な数値（ベクトル）で保存するデータベース。RAGに不可欠。
* **Quantization（量子化）**: モデルの計算精度をあえて下げることで、メモリ消費を抑え、スマホや家庭用PCで動くように軽量化すること。
* **Multi-modal（マルチモーダル）**: テキストだけでなく、画像、音声、動画などを組み合わせて理解・生成できる能力。
* **Agent（エージェント）**: AIが自ら「検索する」「計算する」「コードを実行する」などの道具（ツール）を使い分け、目標を達成しようとする自律的な仕組み。


## 5. 社会的・倫理的側面

* **Alignment（アライメント）**: AIの目的や挙動を、人間の価値観や利益に一致させること。
* **GPU (Graphics Processing Unit)**: AIの膨大な計算を支えるハードウェア。NVIDIA製のチップが主流。
* **Singularity（シンギュラリティ / 技術的特異点）**: AIが人間の知能を上回り、文明が劇的に変化する地点。


