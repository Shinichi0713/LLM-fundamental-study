# 量子化方法

**壊滅的忘却を抑えつつ、限られた計算資源でLLMをファインチューニングする**場合、理論的に可能な手法を網羅するのではなく、**実務上「効く組み合わせ」**に絞るのが最適解です。以下では、**制約付き環境（GPU 1–2枚、VRAM 24GB以下、短時間学習）**を前提に、設計判断の軸と具体策を整理します。

---

## 1. 結論サマリ（実務向け最適戦略）

限られたリソース環境での最適解は、以下の優先順位になります。

**第一選択**

* **QLoRA（4bit量子化 + LoRA）**
* 学習対象は Adapter のみ
* Base model は完全に凍結

**補助的に有効**

* 軽量リハーサル（ごく少量）
* 出力蒸留（LwFの簡易版）

**原則避ける**

* フルファインチューニング
* EWCの厳密実装
* 勾配投影系（計算コスト過大）

---

## 2. なぜ「PEFT + 凍結」が最優先なのか

### 壊滅的忘却の本質

忘却は「知識が消える」のではなく、

> **汎用能力を支えていた重み空間が、新タスク最適化で歪む**
> ことが原因です。

PEFTはこの問題を**構造的に回避**します。

### LoRA / QLoRAの忘却防止メカニズム

* 事前学習済み重み
  → **一切更新しない**
* 新しい知識
  → **低ランク部分空間にのみ格納**

結果として、

* 元の汎用能力：保存
* 新タスク能力：加算的に付与

これは「忘却を抑える」のではなく、
**忘却が起きる経路そのものを遮断**しています。

---

## 3. 限られたリソース前提の実装パターン

### 3.1 QLoRAが事実上の標準解

| 観点   | 効果                        |
| ------ | --------------------------- |
| VRAM   | 7B–13Bを24GB以下で学習可能 |
| 忘却   | Base weights不変            |
| 安定性 | 学習が壊れにくい            |
| 再利用 | Adapter差し替え可能         |

**実務的判断**

* VRAMが厳しいなら「LoRA」ではなく**QLoRA**
* 量子化誤差は Adapter が吸収するため性能劣化は限定的

---

### 3.2 LoRA設計時の忘却耐性パラメータ

忘却をさらに抑えたい場合の設計指針です。

**LoRA適用層**

* Attention の `q, v` のみ
* FFN層は原則触らない

**Rank (r)**

* 小さめ（8〜16）
* 大きすぎると「疑似フル学習」になり忘却リスク増大

**α（スケーリング）**

* r と同程度かやや小さめ

---

## 4. 「最小コスト」で効く補助策

### 4.1 軽量リハーサル（現実解）

フルデータリハーサルは不可能でも、以下は可能です。

**実務的手法**

* 新タスクデータ 95%
* 汎用データ 5%（数千サンプルで十分）

**効果**

* 文法崩壊
* 語彙劣化
* 指示追従能力低下

を明確に抑制します。

---

### 4.2 LwFの簡易版（蒸留）

厳密なLwFでなくても、次が効きます。

* 学習前モデルで同一入力を推論
* 出力 logits を保存
* 新タスク損失 + 蒸留損失

**利点**

* 過去データ不要
* 追加メモリ最小
* 忘却抑制効果は高い

---

## 5. なぜEWC・勾配制御は選ばれないのか

### EWCが実務で使われにくい理由

* Fisher行列計算が重い
* LLM規模では近似が粗くなりやすい
* 効果がLoRAほど安定しない

### 勾配投影系が非現実的な理由

* 勾配次元が巨大
* 計算・実装コストが高すぎる
* GPUメモリを圧迫

**研究用途以外では非推奨**です。

---

## 6. 推奨アーキテクチャ設計テンプレート

限られたリソース環境での**黄金構成**です。

```
Base LLM (frozen, 4bit)
├── LoRA adapters (q, v only)
├── Rank: 8–16
├── α: 8–16
├── Mixed precision (bf16)
└── Optional:
    ├── 5% rehearsal data
    └── Distillation loss (軽量LwF)
```

---

## 7. 最終まとめ

* 壊滅的忘却は「学習戦略の失敗」であり、不可避ではない
* **PEFTは忘却防止と省リソースを同時に達成**
* 限られたリソース環境では
  **QLoRA + 小規模補助策**が最適解
* 正則化や勾配制御は「理論的には美しいが高コスト」

もし次のステップとして、

* QLoRAの具体的PyTorch実装
* 忘却評価用ベンチマーク設計
* Adapter切り替え運用設計

が必要であれば、そこまで踏み込みます。


## LoRA VS QLoRA

要点は「 **何を量子化するか** 」と「 **どこに学習自由度を残すか** 」です。
以下に、**理論・実装・運用の観点**で LoRA と QLoRA の違いを整理します。

---

## 1. 一言での違い

* **LoRA**
  → *重みはFP16/BF16のまま、低ランク行列だけを学習する*
* **QLoRA**
  → *重みを低ビット量子化し、低ランク行列だけを学習する*

学習する対象はどちらも **LoRA Adapterのみ** であり、
**違いは「ベースモデルの表現形式」**です。

---

## 2. 構造的な違い（アーキテクチャ視点）

| 観点         | LoRA             | QLoRA                           |
| ------------ | ---------------- | ------------------------------- |
| Base重み     | FP16 / BF16      | **4bit量子化（NF4など）** |
| 学習対象     | LoRA Adapterのみ | LoRA Adapterのみ                |
| Base重み更新 | なし（凍結）     | なし（凍結）                    |
| 推論時構成   | Base + Adapter   | Base(量子化) + Adapter          |
| 忘却耐性     | 高い             | 高い（同等）                    |

**重要点**
QLoRAは「LoRAの拡張」ではなく、
**LoRA + 量子化インフラ**という位置づけです。

---

## 3. メモリ・計算コスト比較（実務で最重要）

### GPUメモリ使用量（目安）

| モデル | LoRA       | QLoRA                  |
| ------ | ---------- | ---------------------- |
| 7B     | 約14–16GB | **約6–8GB**     |
| 13B    | 約26–30GB | **約10–12GB**   |
| 33B    | 非現実的   | **24GB級で可能** |

QLoRAが「限られたリソースでLLMを扱える」理由はここにあります。

---

## 4. なぜ量子化しても性能が落ちにくいのか

QLoRAでは以下の設計が効いています。

### 4.1 NF4（NormalFloat4）

* 重み分布に特化した4bit表現
* 単純なint4より情報保持率が高い

### 4.2 Double Quantization

* 量子化スケール自体を再度量子化
* メモリ削減と数値安定性の両立

### 4.3 Adapterによる誤差吸収

* 量子化誤差は **LoRA Adapterが補正**
* Base重みを直接更新しないため誤差が増幅しない

---

## 5. 学習安定性と忘却の観点

| 観点             | LoRA       | QLoRA                  |
| ---------------- | ---------- | ---------------------- |
| 壊滅的忘却       | 防止される | 防止される             |
| 学習の壊れにくさ | 安定       | やや注意（量子化由来） |
| ハイパラ調整     | 比較的容易 | やや慎重               |

**実務的結論**

* 忘却耐性は **同等**
* 安定性も近年の実装では差は小さい

---

## 6. 適用シーン別の使い分け

### LoRAを選ぶべき場合

* VRAMに余裕がある（A100等）
* 学習安定性を最優先
* 実装を極力シンプルにしたい

### QLoRAを選ぶべき場合

* VRAMが制約条件（24GB以下）
* 13B以上を扱いたい
* 複数Adapterを量産・切替したい

**現実的には**

> 「QLoRAが使えるならQLoRA、無理ならLoRA」

という判断で問題ありません。

---

## 7. 比較まとめ（意思決定用）

| 項目         | LoRA | QLoRA        |
| ------------ | ---- | ------------ |
| 忘却防止     | ◎   | ◎           |
| VRAM効率     | △   | **◎** |
| 実装難度     | ◎   | ○           |
| スケール耐性 | △   | **◎** |
| 現代的主流   | △   | **◎** |

---

## 8. 本質的な違いの一文まとめ

> **LoRAは「学習自由度を制限する技術」、
> QLoRAは「学習自由度を制限しつつ、表現を圧縮する技術」**

次に進むなら、

* LoRAの適用層設計（q/k/v/ffnの選び方）
* QLoRAの実装落とし穴（bitsandbytes設定）
* Adapterを使ったマルチタスク運用設計

まで踏み込めます。
